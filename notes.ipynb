{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HOW chatGPT interface works ?\n",
    "\n",
    "1) Chat GPT is an app\n",
    "2) It uses Open AI Apis to interact with llms\n",
    "3) these llms could be GPT-3.5, GPT-4 turbo, etc.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But why people don't want to use the open ai api\n",
    "They want their own LLM - Bcoz. of open AI cost incurred with using its API\n",
    "Also, GPT don't has access to private data(of company/org.) and getting real time data from google and internet.\n",
    "\n",
    "But still you can use \"Hugging face Bloom\" as an free open source model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Langchain - framework that allows you to build applications using LLMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU \"langchain[cohere]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I help you today?', additional_kwargs={'id': 'eadea9f0-467f-4931-b5bd-4b1e9e9723d6', 'finish_reason': 'COMPLETE', 'content': 'Hello! How can I help you today?', 'token_count': {'input_tokens': 197.0, 'output_tokens': 9.0}}, response_metadata={'id': 'eadea9f0-467f-4931-b5bd-4b1e9e9723d6', 'finish_reason': 'COMPLETE', 'content': 'Hello! How can I help you today?', 'token_count': {'input_tokens': 197.0, 'output_tokens': 9.0}}, id='run-0124eb2e-333d-481a-a046-7c86a212e382-0', usage_metadata={'input_tokens': 197, 'output_tokens': 9, 'total_tokens': 206})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"COHERE_API_KEY\"):\n",
    "  os.environ[\"COHERE_API_KEY\"] = getpass.getpass(\"Enter API key for Cohere: \")\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = init_chat_model(\"command-r-plus\", model_provider=\"cohere\")\n",
    "\n",
    "model.invoke(\"Hello, world!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# %pip install -qU \"langchain[together]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\" Hello, human! It's nice to see you're interested in starting a conversation with me. I'm here to help answer any questions you might have, so feel free to ask me about a wide range of topics, from general knowledge and facts to programming and technology. I can also assist you with tasks such as setting reminders, providing language translations, and offering real-time weather updates. What can I help you with today?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 92, 'prompt_tokens': 12, 'total_tokens': 104, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'mistralai/Mixtral-8x7B-Instruct-v0.1', 'system_fingerprint': None, 'id': 'nrLRhJt-4yUbBN-935331c98b2a59ae', 'finish_reason': 'stop', 'logprobs': None}, id='run-ba6b1e31-b26e-4d60-ae95-10edd5ee1cb1-0', usage_metadata={'input_tokens': 12, 'output_tokens': 92, 'total_tokens': 104, 'input_token_details': {}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import getpass\n",
    "# import os\n",
    "\n",
    "# if not os.environ.get(\"TOGETHER_API_KEY\"):\n",
    "#   os.environ[\"TOGETHER_API_KEY\"] = getpass.getpass(\"Enter API key for Together AI: \")\n",
    "\n",
    "# from langchain.chat_models import init_chat_model\n",
    "\n",
    "# model2 = init_chat_model(\"mistralai/Mixtral-8x7B-Instruct-v0.1\", model_provider=\"together\")\n",
    "\n",
    "# model2.invoke(\"Hello, world!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I want to open a restaurant for Italian food. Sugges a fency name for it.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template=PromptTemplate(\n",
    "    input_variables=['cuisine'],\n",
    "    template=\"I want to open a restaurant for {cuisine} food. Sugges a fency name for it.\"\n",
    ")\n",
    "\n",
    "prompt_template.format(cuisine=\"Italian\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Here are a few potential names for a fancy Mexican restaurant:\\n\\n- La Casa de los Sabores (The House of Flavors)\\n- El Comedor Elegante (The Elegant Dining Room)\\n- La Mesa de México (The Table of Mexico)\\n- Los Sabores de la Vida (The Flavors of Life)\\n- La Cocina de las Maravillas (The Wonder Kitchen)\\n- El Paraíso Mexicano (The Mexican Paradise)\\n- La Fiesta de los Sentidos (The Feast of the Senses)\\n- Los Placeres de la Mesa (The Pleasures of the Table)\\n- La Cantina de los Sueños (The Tavern of Dreams)\\n- El Rincón de México (The Corner of Mexico)'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concepts of chain in langchain\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "chain=LLMChain(llm=model, prompt=prompt_template)\n",
    "chain.run(\"Mexican\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating sequential chain\n",
    "1) above we got name of restraunt as the first chain\n",
    "2) now, we can have the second chain where u pass restraunt name as input \n",
    "and it will give food menu items to include in your restraunt\n",
    "\n",
    "what are the sequential chain ?\n",
    "Nothinh just the output of first thing will act as input of other thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a list of suggested food menu items for an Indian restaurant with a fancy name like \"Masala Mahal\":\n",
      "\n",
      "- Butter Chicken Supreme\n",
      "- Dal Makhani Royale\n",
      "- Palak Paneer Delight\n",
      "- Malai Kofta Extravaganza\n",
      "- Chicken Tikka Masala Fiesta\n",
      "- Lamb Korma Celebration\n",
      "- Shrimp Biryani Festival\n",
      "- Vegetable Kebab Sensation\n",
      "- Naan Bread Symphony\n",
      "- Gulab Jamun Finale\n",
      "\n",
      " These menu item names are designed to be attention-grabbing and elegant, befitting the ambiance of a fancy Indian restaurant.\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template_name=PromptTemplate(\n",
    "    input_variables=['cuisine'],\n",
    "    template=\"I want to open a restaurant for {cuisine} food. Sugges a fency name for it(only one), just give the name in response.\"\n",
    ")\n",
    "\n",
    "# add a ouptut key here for the next chain to get it \n",
    "name_chain=LLMChain(llm=model, prompt=prompt_template_name, output_key='restaurant_name')\n",
    "\n",
    "prompt_template_items=PromptTemplate(\n",
    "    input_variables=['restaurant_name'],\n",
    "    template=\" Suggest some food menu items(names only) for restaraunt {restaurant_name} food. Return in a list format, just give the list items nothing else.\"\n",
    ")\n",
    "\n",
    "food_items_chain=LLMChain(llm=model, prompt=prompt_template_items, output_key='menu_items')\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "# Creating a sequential chain for above two chains\n",
    "\n",
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "chain=SimpleSequentialChain(chains = [name_chain, food_items_chain])\n",
    "\n",
    "response=chain.run(\"Indian\")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above was a simple sequential chain -> notice the output of first chain(i.e. the Restaurant name is not outputted in the result, its hidden as of now)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get both the output of first and second chain, and also provide multiple inputs to a chain, Use a different method called -> 'Sequential Chain' instead of 'simple Sequential chain'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_133993/728699918.py:11: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  seq_chain({'cuisine':'Arabic'})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cuisine': 'Arabic',\n",
       " 'restaurant_name': 'Here is a suggestion for a fancy name for an Arabic food restaurant: \"Al Sultan\"',\n",
       " 'menu_items': 'Here are some menu item suggestions for an Arabic food restaurant named \"Al Sultan\":\\n\\n- Appetizers:\\n    - Sultan\\'s Mezze Platter\\n    - Hummus with Lamb\\n    - Warak Enab\\n    - Batata Harra\\n- Salads:\\n    - Fattoush Salad\\n    - Tabbouleh\\n    - Cucumber Yogurt Salad\\n- Main Courses:\\n    - Lamb Kabsa\\n    - Chicken Shawarma\\n    - Mixed Grill Platter\\n    - Falafel Wrap\\n- Desserts:\\n    - Baklava Ice Cream\\n    - Kunafa Cups\\n    - Dates with Cream\\n    - Arabic Coffee Mousse\\n- Beverages:\\n    - Mint Lemonade\\n    - Arabian Nights Iced Tea\\n    - Rose Milk\\n    - Qahwa (Arabic Coffee)\\n\\n These suggestions offer a mix of traditional Arabic dishes and modern interpretations, providing a range of options for customers to choose from.'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "\n",
    "seq_chain=SequentialChain(\n",
    "    chains=[name_chain, food_items_chain],\n",
    "    input_variables=['cuisine'],\n",
    "    output_variables=['restaurant_name', 'menu_items'],\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# no run here to run a sequential chain\n",
    "seq_chain({'cuisine':'Arabic'})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
